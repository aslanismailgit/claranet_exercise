{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import pickle\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data and remove outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15375, 4) (15375,) (15375,)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"./data/df_slow.csv\")\n",
    "summary = df[\"query_time_ns\"]\\\n",
    "    .describe(percentiles=[0.10, 0.20, 0.30, 0.40, 0.50, 0.60, 0.70, 0.80, 0.90, 0.95, 0.99, 1.00])\n",
    "mask = (df[\"query_time_ns\"]<summary[\"99%\"])\n",
    "sum(mask)\n",
    "\n",
    "df = df[mask]\n",
    "\n",
    "X = df[\"clean_query\"]\n",
    "y = df['query_time_ns']\n",
    "print(df.shape, X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction TF-IDF \n",
    "TF-IDF works by penalizing the common words by assigning them lower \n",
    "weights while giving importance to words which are rare in the entire \n",
    "corpus but appear in good numbers in few documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For cross validation, here I keep the valid in the trains set, cv will automaticly seperate valid set for each iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((13837,), (1538,), (13837,), (1538,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain, xtest, ytrain, ytest = train_test_split(X, y, test_size=0.1)\n",
    "# xvalid, xtest, yvalid, ytest = train_test_split(xvalid, yvalid, test_size=0.3)\n",
    "xtrain.shape,  xtest.shape, ytrain.shape, ytest.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TfidfVectorizer have to fit only train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features -tokens- in train set : 922\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((13837, 922), (1538, 922), (13837,), (1538,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf = tfidf_vectorizer.fit(xtrain)\n",
    "\n",
    "xtrain_tfidf = tfidf_vectorizer.transform(xtrain)\n",
    "xtest_tfidf = tfidf_vectorizer.transform(xtest)\n",
    "\n",
    "print(\"Number of features -tokens- in train set :\", len(tfidf.get_feature_names()))\n",
    "\n",
    "xtrain_tfidf.shape, xtest_tfidf.shape, ytrain.shape, ytest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./models/tfidf_vectorizer.sav']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib_tfidf_vectorizer = \"./models/tfidf_vectorizer.sav\"\n",
    "joblib.dump(tfidf_vectorizer, joblib_tfidf_vectorizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don't need standadization since \"TfidfVectorizer combines all \n",
    "the options of CountVectorizer and TfidfTransformer in a single model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare a function to evaluate models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function to evaluate each model. I will evaluate each model by size, prediction time, RMSE, MAE and r2 for train, validation and test sets.\n",
    "The coefficient of determination: 1 is perfect prediction\n",
    "R2  computes how much better the regression line fits the data \n",
    "than the mean line.\n",
    "Another way to look at this formula is to compare the variance \n",
    "around the mean line to the variation around the regression line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model, x, y, data_type, prn = False):\n",
    "    start = time.time()\n",
    "    pred = model.predict(x)\n",
    "    pred_time = np.round((time.time() - start),4)\n",
    "    if prn:\n",
    "        print(f\"{data_type} - Root mean squared error     : {(mean_squared_error(y, pred, squared=False)):.2f}\")\n",
    "        print(f\"{data_type} - Mean absolute error         : {(mean_absolute_error(y, pred)):.2f}\")\n",
    "        print(f\"{data_type} - Coefficient of determination: {(r2_score(y, pred)):.2f}\")\n",
    "        print(f\"{data_type} - Time elapsed                : {pred_time}\\n\")\n",
    "    return np.round(mean_squared_error(y, pred, squared=False),1), \\\n",
    "            np.round(mean_absolute_error(y, pred),1), \\\n",
    "            np.round(r2_score(y, pred),2), \\\n",
    "            pred_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Size</th>\n",
       "      <th>Train RMSE</th>\n",
       "      <th>Train MAE</th>\n",
       "      <th>Train R2</th>\n",
       "      <th>Time Elapsed</th>\n",
       "      <th>Valid RMSE</th>\n",
       "      <th>Valid MAE</th>\n",
       "      <th>Valid R2</th>\n",
       "      <th>Valid Elapsed</th>\n",
       "      <th>Test RMSE</th>\n",
       "      <th>Test MAE</th>\n",
       "      <th>Test R2</th>\n",
       "      <th>Test Elapsed</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>linreg</th>\n",
       "      <td>7480</td>\n",
       "      <td>114889.6</td>\n",
       "      <td>40494.6</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>131939.0</td>\n",
       "      <td>47322.9</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.0011</td>\n",
       "      <td>136721.9</td>\n",
       "      <td>50345.4</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.0006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svc_regr</th>\n",
       "      <td>7627</td>\n",
       "      <td>891923.7</td>\n",
       "      <td>425866.1</td>\n",
       "      <td>-0.29</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>887686.8</td>\n",
       "      <td>426950.8</td>\n",
       "      <td>-0.30</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>868634.7</td>\n",
       "      <td>421458.7</td>\n",
       "      <td>-0.31</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rand_for_reg</th>\n",
       "      <td>24827326</td>\n",
       "      <td>68386.5</td>\n",
       "      <td>20902.1</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.1362</td>\n",
       "      <td>120462.3</td>\n",
       "      <td>36910.6</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.0531</td>\n",
       "      <td>127260.4</td>\n",
       "      <td>38965.4</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.0267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ada_boost_reg</th>\n",
       "      <td>12763</td>\n",
       "      <td>235785.3</td>\n",
       "      <td>150016.3</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.0104</td>\n",
       "      <td>241501.9</td>\n",
       "      <td>153238.2</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>237806.8</td>\n",
       "      <td>154167.0</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grd_boost_reg</th>\n",
       "      <td>119711</td>\n",
       "      <td>109424.9</td>\n",
       "      <td>41811.4</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.0131</td>\n",
       "      <td>118453.6</td>\n",
       "      <td>44572.5</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>125485.8</td>\n",
       "      <td>46833.9</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.0040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb_reg</th>\n",
       "      <td>218735</td>\n",
       "      <td>70951.6</td>\n",
       "      <td>25194.7</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.0076</td>\n",
       "      <td>122792.2</td>\n",
       "      <td>36972.1</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>132979.8</td>\n",
       "      <td>39993.4</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Size  Train RMSE  Train MAE  Train R2  Time Elapsed  \\\n",
       "Model                                                                    \n",
       "linreg             7480    114889.6    40494.6      0.98        0.0020   \n",
       "svc_regr           7627    891923.7   425866.1     -0.29        0.0010   \n",
       "rand_for_reg   24827326     68386.5    20902.1      0.99        0.1362   \n",
       "ada_boost_reg     12763    235785.3   150016.3      0.91        0.0104   \n",
       "grd_boost_reg    119711    109424.9    41811.4      0.98        0.0131   \n",
       "xgb_reg          218735     70951.6    25194.7      0.99        0.0076   \n",
       "\n",
       "               Valid RMSE  Valid MAE  Valid R2  Valid Elapsed  Test RMSE  \\\n",
       "Model                                                                      \n",
       "linreg           131939.0    47322.9      0.97         0.0011   136721.9   \n",
       "svc_regr         887686.8   426950.8     -0.30         0.0010   868634.7   \n",
       "rand_for_reg     120462.3    36910.6      0.98         0.0531   127260.4   \n",
       "ada_boost_reg    241501.9   153238.2      0.90         0.0010   237806.8   \n",
       "grd_boost_reg    118453.6    44572.5      0.98         0.0040   125485.8   \n",
       "xgb_reg          122792.2    36972.1      0.98         0.0040   132979.8   \n",
       "\n",
       "               Test MAE  Test R2  Test Elapsed  \n",
       "Model                                           \n",
       "linreg          50345.4     0.97        0.0006  \n",
       "svc_regr       421458.7    -0.31        0.0000  \n",
       "rand_for_reg    38965.4     0.97        0.0267  \n",
       "ada_boost_reg  154167.0     0.90        0.0000  \n",
       "grd_boost_reg   46833.9     0.97        0.0040  \n",
       "xgb_reg         39993.4     0.97        0.0010  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_performance = pd.read_csv(\"./data/df_performance.csv\")\n",
    "df_performance.set_index(\"Model\", inplace=True)\n",
    "df_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I picked 2 models to ensemble: XGBRegressor and RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "             importance_type='gain', interaction_constraints='',\n",
       "             learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "             n_estimators=100, n_jobs=8, num_parallel_tree=1, random_state=0,\n",
       "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "             tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "xgb_reg = XGBRegressor()\n",
    "xgb_reg.fit(xtrain_tfidf, ytrain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rand_forest_reg = RandomForestRegressor()\n",
    "rand_forest_reg.fit(xtrain_tfidf, ytrain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_ensamble_model(model1, model2, x, y, data_type, prn = False):\n",
    "    start = time.time()\n",
    "    pred1 = model1.predict(x)\n",
    "    pred2 = model2.predict(x)\n",
    "    pred = (pred1+pred2)/2\n",
    "    pred_time = np.round((time.time() - start),4)\n",
    "    if prn:\n",
    "        print(f\"{data_type} - Root mean squared error     : {(mean_squared_error(y, pred, squared=False)):.2f}\")\n",
    "        print(f\"{data_type} - Mean absolute error         : {(mean_absolute_error(y, pred)):.2f}\")\n",
    "        print(f\"{data_type} - Coefficient of determination: {(r2_score(y, pred)):.2f}\")\n",
    "        print(f\"{data_type} - Time elapsed                : {pred_time}\\n\")\n",
    "    return np.round(mean_squared_error(y, pred, squared=False),1), \\\n",
    "            np.round(mean_absolute_error(y, pred),1), \\\n",
    "            np.round(r2_score(y, pred),2), \\\n",
    "            pred_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensemble does not improve the test r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Root mean squared error     : 73120.51\n",
      "Train - Mean absolute error         : 23735.29\n",
      "Train - Coefficient of determination: 0.99\n",
      "Train - Time elapsed                : 0.2188\n",
      "\n",
      "Test - Root mean squared error     : 131031.85\n",
      "Test - Mean absolute error         : 39456.78\n",
      "Test - Coefficient of determination: 0.97\n",
      "Test - Time elapsed                : 0.0484\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tr_rmse, tr_mae, tr_r2, tr_time_elapsed  = eval_ensamble_model(xgb_reg, rand_forest_reg,  xtrain_tfidf, ytrain, data_type=\"Train\", prn = True)\n",
    "test_rmse, test_mae, test_r2, test_time_elapsed  = eval_ensamble_model(xgb_reg, rand_forest_reg, xtest_tfidf, ytest, data_type=\"Test\", prn = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid search and Random Search on Cross Validation Sets for Best Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from pprint import pprint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBRegressor\n",
    "params = {\n",
    " 'max_depth':range(3,6,1),\n",
    " 'min_child_weight':range(1,3,1)\n",
    "}\n",
    "xgb_reg_grid_searc = GridSearchCV(estimator = XGBRegressor( learning_rate =0.1, n_estimators=140, max_depth=5),\n",
    "                                    param_grid = params, \n",
    "                                    scoring=\"r2\",\n",
    "                                    verbose=2\n",
    "                                 )\n",
    "# pprint(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "[CV] END ....................max_depth=3, min_child_weight=1; total time=   0.8s\n",
      "[CV] END ....................max_depth=3, min_child_weight=1; total time=   0.8s\n",
      "[CV] END ....................max_depth=3, min_child_weight=1; total time=   0.8s\n",
      "[CV] END ....................max_depth=3, min_child_weight=1; total time=   0.8s\n",
      "[CV] END ....................max_depth=3, min_child_weight=1; total time=   0.8s\n",
      "[CV] END ....................max_depth=3, min_child_weight=2; total time=   0.8s\n",
      "[CV] END ....................max_depth=3, min_child_weight=2; total time=   0.8s\n",
      "[CV] END ....................max_depth=3, min_child_weight=2; total time=   0.8s\n",
      "[CV] END ....................max_depth=3, min_child_weight=2; total time=   0.8s\n",
      "[CV] END ....................max_depth=3, min_child_weight=2; total time=   0.8s\n",
      "[CV] END ....................max_depth=4, min_child_weight=1; total time=   1.0s\n",
      "[CV] END ....................max_depth=4, min_child_weight=1; total time=   1.1s\n",
      "[CV] END ....................max_depth=4, min_child_weight=1; total time=   1.1s\n",
      "[CV] END ....................max_depth=4, min_child_weight=1; total time=   1.1s\n",
      "[CV] END ....................max_depth=4, min_child_weight=1; total time=   1.1s\n",
      "[CV] END ....................max_depth=4, min_child_weight=2; total time=   1.1s\n",
      "[CV] END ....................max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END ....................max_depth=4, min_child_weight=2; total time=   1.1s\n",
      "[CV] END ....................max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END ....................max_depth=4, min_child_weight=2; total time=   1.0s\n",
      "[CV] END ....................max_depth=5, min_child_weight=1; total time=   1.3s\n",
      "[CV] END ....................max_depth=5, min_child_weight=1; total time=   1.4s\n",
      "[CV] END ....................max_depth=5, min_child_weight=1; total time=   1.4s\n",
      "[CV] END ....................max_depth=5, min_child_weight=1; total time=   1.3s\n",
      "[CV] END ....................max_depth=5, min_child_weight=1; total time=   1.3s\n",
      "[CV] END ....................max_depth=5, min_child_weight=2; total time=   1.3s\n",
      "[CV] END ....................max_depth=5, min_child_weight=2; total time=   1.3s\n",
      "[CV] END ....................max_depth=5, min_child_weight=2; total time=   1.3s\n",
      "[CV] END ....................max_depth=5, min_child_weight=2; total time=   1.3s\n",
      "[CV] END ....................max_depth=5, min_child_weight=2; total time=   1.8s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                    colsample_bylevel=None,\n",
       "                                    colsample_bynode=None,\n",
       "                                    colsample_bytree=None, gamma=None,\n",
       "                                    gpu_id=None, importance_type='gain',\n",
       "                                    interaction_constraints=None,\n",
       "                                    learning_rate=0.1, max_delta_step=None,\n",
       "                                    max_depth=5, min_child_weight=None,\n",
       "                                    missing=nan, monotone_constraints=None,\n",
       "                                    n_estimators=140, n_jobs=None,\n",
       "                                    num_parallel_tree=None, random_state=None,\n",
       "                                    reg_alpha=None, reg_lambda=None,\n",
       "                                    scale_pos_weight=None, subsample=None,\n",
       "                                    tree_method=None, validate_parameters=None,\n",
       "                                    verbosity=None),\n",
       "             param_grid={'max_depth': range(3, 6),\n",
       "                         'min_child_weight': range(1, 3)},\n",
       "             scoring='r2', verbose=2)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_reg_grid_searc.fit(xtrain_tfidf, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 4, 'min_child_weight': 2}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_reg_grid_searc.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Automaticly proceed to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth = xgb_reg_grid_searc.best_params_[\"max_depth\"]\n",
    "min_child_weight = xgb_reg_grid_searc.best_params_[\"min_child_weight\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "             importance_type='gain', interaction_constraints='',\n",
       "             learning_rate=0.300000012, max_delta_step=0, max_depth=4,\n",
       "             min_child_weight=2, missing=nan, monotone_constraints='()',\n",
       "             n_estimators=100, n_jobs=8, num_parallel_tree=1, random_state=0,\n",
       "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "             tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_model = XGBRegressor(max_depth = max_depth, min_child_weight = min_child_weight)\n",
    "xgb_model.fit(xtrain_tfidf, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./models/xgb_model.sav']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib_xgb_model = \"./models/xgb_model.sav\"\n",
    "joblib.dump(xgb_model, joblib_xgb_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': [5, 10, 15, 20, 25, 30], 'min_samples_leaf': [1, 2, 5, 10]}\n"
     ]
    }
   ],
   "source": [
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(5, 30, num = 6)]\n",
    "\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 5, 10]\n",
    "\n",
    "params = {'max_depth': max_depth,\n",
    "          'min_samples_leaf': min_samples_leaf}\n",
    "\n",
    "pprint(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "[CV] END ...................max_depth=25, min_samples_leaf=2; total time=  20.8s\n",
      "[CV] END ...................max_depth=25, min_samples_leaf=2; total time=  21.5s\n",
      "[CV] END ...................max_depth=25, min_samples_leaf=2; total time=  21.6s\n",
      "[CV] END ...................max_depth=25, min_samples_leaf=2; total time=  21.8s\n",
      "[CV] END ...................max_depth=25, min_samples_leaf=2; total time=  21.7s\n",
      "[CV] END ...................max_depth=15, min_samples_leaf=2; total time=  16.2s\n",
      "[CV] END ...................max_depth=15, min_samples_leaf=2; total time=  17.3s\n",
      "[CV] END ...................max_depth=15, min_samples_leaf=2; total time=  16.9s\n",
      "[CV] END ...................max_depth=15, min_samples_leaf=2; total time=  16.3s\n",
      "[CV] END ...................max_depth=15, min_samples_leaf=2; total time=  16.7s\n",
      "[CV] END ...................max_depth=10, min_samples_leaf=5; total time=  10.7s\n",
      "[CV] END ...................max_depth=10, min_samples_leaf=5; total time=  10.5s\n",
      "[CV] END ...................max_depth=10, min_samples_leaf=5; total time=  11.1s\n",
      "[CV] END ...................max_depth=10, min_samples_leaf=5; total time=  10.5s\n",
      "[CV] END ...................max_depth=10, min_samples_leaf=5; total time=  10.3s\n",
      "[CV] END ..................max_depth=10, min_samples_leaf=10; total time=   9.8s\n",
      "[CV] END ..................max_depth=10, min_samples_leaf=10; total time=   9.4s\n",
      "[CV] END ..................max_depth=10, min_samples_leaf=10; total time=  10.0s\n",
      "[CV] END ..................max_depth=10, min_samples_leaf=10; total time=   9.8s\n",
      "[CV] END ..................max_depth=10, min_samples_leaf=10; total time=   9.1s\n",
      "[CV] END ...................max_depth=15, min_samples_leaf=5; total time=  14.5s\n",
      "[CV] END ...................max_depth=15, min_samples_leaf=5; total time=  13.8s\n",
      "[CV] END ...................max_depth=15, min_samples_leaf=5; total time=  13.1s\n",
      "[CV] END ...................max_depth=15, min_samples_leaf=5; total time=  13.1s\n",
      "[CV] END ...................max_depth=15, min_samples_leaf=5; total time=  12.9s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=RandomForestRegressor(), n_iter=5,\n",
       "                   param_distributions={'max_depth': [5, 10, 15, 20, 25, 30],\n",
       "                                        'min_samples_leaf': [1, 2, 5, 10]},\n",
       "                   verbose=2)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This time RandomizedSearchCV because there are too many params to search!\n",
    "rand_forest_reg_grid_searc = RandomizedSearchCV(\n",
    "                                estimator = RandomForestRegressor(), \n",
    "                                param_distributions = params, \n",
    "                                n_iter = 5, \n",
    "                                cv = 5, \n",
    "                                verbose=2)\n",
    "rand_forest_reg_grid_searc.fit(xtrain_tfidf, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'min_samples_leaf': 2, 'max_depth': 15}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_forest_reg_grid_searc.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth = rand_forest_reg_grid_searc.best_params_[\"max_depth\"]\n",
    "min_samples_leaf = rand_forest_reg_grid_searc.best_params_[\"min_samples_leaf\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(max_depth=15, min_samples_leaf=2)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_forest_model = RandomForestRegressor(max_depth = max_depth, min_samples_leaf = min_samples_leaf)\n",
    "rand_forest_model.fit(xtrain_tfidf, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./models/rand_forest_model.sav']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib_rand_forest_model = \"./models/rand_forest_model.sav\"\n",
    "joblib.dump(rand_forest_model, joblib_rand_forest_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble Results with Optimized Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Root mean squared error     : 84717.06\n",
      "Train - Mean absolute error         : 28120.54\n",
      "Train - Coefficient of determination: 0.99\n",
      "Train - Time elapsed                : 0.148\n",
      "\n",
      "Test - Root mean squared error     : 126089.19\n",
      "Test - Mean absolute error         : 39514.49\n",
      "Test - Coefficient of determination: 0.97\n",
      "Test - Time elapsed                : 0.029\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tr_rmse, tr_mae, tr_r2, tr_time_elapsed  = eval_ensamble_model(xgb_model, rand_forest_model,  xtrain_tfidf, ytrain, data_type=\"Train\", prn = True)\n",
    "test_rmse, test_mae, test_r2, test_time_elapsed  = eval_ensamble_model(xgb_model, rand_forest_model, xtest_tfidf, ytest, data_type=\"Test\", prn = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Regressor Results After Parameter Search : Single Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rand_forest_model size                         : 8415139\n",
      "Train - Root mean squared error     : 85607.89\n",
      "Train - Mean absolute error         : 26903.64\n",
      "Train - Coefficient of determination: 0.99\n",
      "Train - Time elapsed                : 0.127\n",
      "\n",
      "Test - Root mean squared error     : 127039.93\n",
      "Test - Mean absolute error         : 40441.75\n",
      "Test - Coefficient of determination: 0.97\n",
      "Test - Time elapsed                : 0.022\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_name = \"rand_forest_model\"\n",
    "p = pickle.dumps(eval(model_name))\n",
    "model_size = sys.getsizeof(p)\n",
    "print(f\"{model_name} size                         : {model_size}\")\n",
    "tr_rmse, tr_mae, tr_r2, tr_time_elapsed  = eval_model(eval(model_name), xtrain_tfidf, ytrain, data_type=\"Train\", prn=True)\n",
    "test_rmse, test_mae, test_r2, test_time_elapsed  = eval_model(eval(model_name), xtest_tfidf, ytest, data_type=\"Test\", prn=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBRegressor Results After Parameter Search : Single Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgb_model size                         : 139305\n",
      "Train - Root mean squared error     : 85736.23\n",
      "Train - Mean absolute error         : 30218.58\n",
      "Train - Coefficient of determination: 0.99\n",
      "Train - Time elapsed                : 0.01\n",
      "\n",
      "Test - Root mean squared error     : 129014.32\n",
      "Test - Mean absolute error         : 39822.54\n",
      "Test - Coefficient of determination: 0.97\n",
      "Test - Time elapsed                : 0.004\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_name = \"xgb_model\"\n",
    "p = pickle.dumps(eval(model_name))\n",
    "model_size = sys.getsizeof(p)\n",
    "print(f\"{model_name} size                         : {model_size}\")\n",
    "tr_rmse, tr_mae, tr_r2, tr_time_elapsed  = eval_model(eval(model_name), xtrain_tfidf, ytrain, data_type=\"Train\", prn=True)\n",
    "test_rmse, test_mae, test_r2, test_time_elapsed  = eval_model(eval(model_name), xtest_tfidf, ytest, data_type=\"Test\", prn=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I will go with xgboost regressor. So I will use the entire data set to create a new model in a pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:x_env_con] *",
   "language": "python",
   "name": "conda-env-x_env_con-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
